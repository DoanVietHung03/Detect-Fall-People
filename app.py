import streamlit as st
import cv2
import os
import glob
import shutil
import tempfile
import threading
import queue
import time
from inference import FallDetector

# --- C·∫§U H√åNH ---
st.set_page_config(page_title="H·ªá th·ªëng Ph√°t hi·ªán Ng√£ (Optimized)", layout="wide", page_icon="‚ö°")
VIDEO_DIR = "samples"
SNAPSHOT_DIR = "snapshots"

# --- CSS ---
st.markdown("""
    <style>
        .stImage { border: 2px solid #ddd; border-radius: 5px; }
        div[data-testid="stMetricValue"] { font-size: 20px; }
    </style>
""", unsafe_allow_html=True)

# --- QU·∫¢N L√ù STATE ---
if 'selected_video_path' not in st.session_state:
    st.session_state['selected_video_path'] = None
if 'stop_thread' not in st.session_state:
    st.session_state['stop_thread'] = False

# --- CLASS X·ª¨ L√ù ƒêA LU·ªíNG (THREADING) ---
class VideoProcessor(threading.Thread):
    def __init__(self, video_path, conf_thresh, lstm_thresh, frame_queue, result_queue):
        super().__init__()
        self.video_path = video_path
        self.conf_thresh = conf_thresh
        self.lstm_thresh = lstm_thresh
        self.frame_queue = frame_queue
        self.result_queue = result_queue
        self.stopped = False
        self.detector = None

    def run(self):
        # Kh·ªüi t·∫°o model trong lu·ªìng ri√™ng ƒë·ªÉ tr√°nh lag UI
        self.detector = FallDetector(conf_threshold=self.conf_thresh, lstm_threshold=self.lstm_thresh)
        cap = cv2.VideoCapture(self.video_path)
        
        frame_idx = 0
        SKIP_FRAMES = 2 # X·ª≠ l√Ω 1 frame, b·ªè qua 2 frame (TƒÉng t·ªëc)

        while not self.stopped and cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_idx += 1
            if frame_idx % (SKIP_FRAMES + 1) != 0:
                continue

            # 1. Resize ·∫£nh ƒë·ªÉ tƒÉng t·ªëc Inference (Quan tr·ªçng!)
            # YOLO chu·∫©n l√† 640, n·∫øu ƒë∆∞a 1080p v√†o s·∫Ω r·∫•t ch·∫≠m
            h, w = frame.shape[:2]
            scale = 640 / w
            new_h = int(h * scale)
            resized_frame = cv2.resize(frame, (640, new_h))

            # 2. C·∫≠p nh·∫≠t ng∆∞·ª°ng (n·∫øu user ƒë·ªïi slider)
            self.detector.conf_threshold = self.conf_thresh
            self.detector.lstm_threshold = self.lstm_thresh

            # 3. Ch·∫°y AI
            processed_frame, fall_count, snap_dir = self.detector.process_frame(resized_frame)

            # 4. ƒê·∫©y k·∫øt qu·∫£ v√†o h√†ng ƒë·ª£i (Queue)
            # X√≥a c≈© n·∫øu ƒë·∫ßy ƒë·ªÉ lu√¥n l·∫•y frame m·ªõi nh·∫•t (Real-time)
            if self.result_queue.full():
                try: self.result_queue.get_nowait()
                except queue.Empty: pass
            
            self.result_queue.put({
                'frame': processed_frame,
                'fall_count': fall_count,
                'snap_dir': snap_dir,
                'has_new_fall': fall_count > 0 # C·ªù b√°o hi·ªáu c√≥ ng√£ ƒë·ªÉ UI update gallery
            })
            
        cap.release()
        self.stopped = True

    def stop(self):
        self.stopped = True

# --- UI FUNCTIONS ---
def clear_history():
    if os.path.exists(SNAPSHOT_DIR):
        try: shutil.rmtree(SNAPSHOT_DIR); os.makedirs(SNAPSHOT_DIR)
        except: pass
    else: os.makedirs(SNAPSHOT_DIR)

def get_video_files():
    if not os.path.exists(VIDEO_DIR): os.makedirs(VIDEO_DIR); return []
    return sorted([f for f in os.listdir(VIDEO_DIR) if f.endswith(('.mp4', '.avi', '.mkv'))])

# ================= SIDEBAR =================
with st.sidebar:
    st.header("‚ö° C·∫•u h√¨nh & T·ªëi ∆∞u")
    conf_thresh = st.slider("Confidence YOLO", 0.3, 1.0, 0.85) 
    lstm_thresh = st.slider("Ng∆∞·ª°ng LSTM", 0.5, 0.99, 0.75)
    
    st.divider()
    st.subheader("Video")
    for vid in get_video_files():
        if st.button(f"‚ñ∂ {vid}"):
            st.session_state['selected_video_path'] = os.path.join(VIDEO_DIR, vid)
            clear_history()
            st.rerun()

    uploaded = st.file_uploader("Upload Video", type=['mp4'])
    if uploaded:
        tfile = tempfile.NamedTemporaryFile(delete=False)
        tfile.write(uploaded.read())
        st.session_state['selected_video_path'] = tfile.name

# ================= MAIN UI =================
st.title("‚ö° AI Fall Detection (Multi-threaded)")
col_video, col_info = st.columns([3, 1.5])

# Placeholder
with col_video:
    video_ph = st.empty()
with col_info:
    status_ph = st.empty()
    st.divider()
    gallery_ph = st.empty() # Gallery placeholder
    stop_btn = st.button("‚èπ D·ª™NG", type="primary")

# Logic ch√≠nh
video_path = st.session_state.get('selected_video_path')

if video_path and not stop_btn:
    # H√†ng ƒë·ª£i giao ti·∫øp gi·ªØa 2 lu·ªìng
    frame_queue = queue.Queue(maxsize=1) 
    result_queue = queue.Queue(maxsize=2) # Ch·ªâ gi·ªØ t·ªëi ƒëa 2 k·∫øt qu·∫£ ch·ªù ƒë·ªÉ ƒë·∫£m b·∫£o realtime

    # Kh·ªüi ƒë·ªông lu·ªìng AI
    processor = VideoProcessor(video_path, conf_thresh, lstm_thresh, frame_queue, result_queue)
    processor.start()

    st.toast(f"ƒêang kh·ªüi ƒë·ªông AI Engine...", icon="üöÄ")
    
    # Bi·∫øn cache ƒë·ªÉ tr√°nh ƒë·ªçc ·ªï c·ª©ng li√™n t·ª•c
    cached_images = []
    last_update_gallery = 0

    while processor.is_alive():
        try:
            # Ch·ªù l·∫•y k·∫øt qu·∫£ t·ª´ lu·ªìng AI (timeout 0.1s ƒë·ªÉ kh√¥ng treo UI)
            data = result_queue.get(timeout=0.1)
            
            # 1. Hi·ªÉn th·ªã Video
            frame_rgb = cv2.cvtColor(data['frame'], cv2.COLOR_BGR2RGB)
            video_ph.image(frame_rgb, channels="RGB", width='content')

            # 2. Hi·ªÉn th·ªã Tr·∫°ng th√°i
            if data['fall_count'] > 0:
                status_ph.error(f"üö® PH√ÅT HI·ªÜN: {data['fall_count']} NG∆Ø·ªúI NG√É!", icon="‚ö†Ô∏è")
            else:
                status_ph.success("‚úÖ ƒêang gi√°m s√°t...", icon="üõ°Ô∏è")

            # 3. C·∫≠p nh·∫≠t Gallery (Ch·ªâ update khi c√≥ ng√£ ho·∫∑c m·ªói 5 gi√¢y 1 l·∫ßn)
            # T·ªêI ∆ØU: Kh√¥ng g·ªçi glob.glob m·ªói frame!
            current_time = time.time()
            if data['has_new_fall'] and (current_time - last_update_gallery > 1.0):
                last_update_gallery = current_time
                if os.path.exists(SNAPSHOT_DIR):
                    cached_images = sorted(glob.glob(os.path.join(SNAPSHOT_DIR, '*.jpg')), key=os.path.getmtime, reverse=True)
                
                with gallery_ph.container():
                    st.write(f"üì∏ **B·∫±ng ch·ª©ng ({len(cached_images)})**")
                    if cached_images:
                        # Ch·ªâ hi·ªán 3 ·∫£nh m·ªõi nh·∫•t ƒë·ªÉ ƒë·ª° lag
                        cols = st.columns(3)
                        for idx, img_path in enumerate(cached_images[:3]):
                            cols[idx].image(img_path, caption=os.path.basename(img_path))

        except queue.Empty:
            continue
    
    processor.stop()
    processor.join()
    st.success("K·∫øt th√∫c video.")

elif stop_btn:
    st.session_state['stop_thread'] = True
    st.write("H·ªá th·ªëng ƒë√£ d·ª´ng.")
else:
    st.info("üëà Ch·ªçn video ƒë·ªÉ b·∫Øt ƒë·∫ßu.")