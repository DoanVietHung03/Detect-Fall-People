# api_server.py
from fastapi import FastAPI
from fastapi.responses import StreamingResponse
from fastapi.staticfiles import StaticFiles
import cv2
import uvicorn
import os
import glob
import time
from pydantic import BaseModel
from inference import FallDetector

app = FastAPI()

# --- C·∫§U H√åNH ---
SNAPSHOT_DIR = "snapshots"
if not os.path.exists(SNAPSHOT_DIR): os.makedirs(SNAPSHOT_DIR)

# Mount th∆∞ m·ª•c ·∫£nh ƒë·ªÉ Dashboard c√≥ th·ªÉ xem qua URL
app.mount("/snapshots", StaticFiles(directory=SNAPSHOT_DIR), name="snapshots")

# --- GLOBAL STATE ---
current_settings = {
    "conf": 0.7,
    "lstm": 0.7,
    "fall_detected_now": False # Tr·∫°ng th√°i t·ª©c th·ªùi ƒë·ªÉ dashboard c·∫£nh b√°o
}

# Kh·ªüi t·∫°o model
print("‚è≥ ƒêang t·∫£i model AI...")
detector = FallDetector(
    model_pose='weights/yolo11m-pose.pt',
    model_lstm='weights/lstm_fall_model.pth'
)
print("‚úÖ AI ƒë√£ s·∫µn s√†ng!")

class Settings(BaseModel):
    conf: float
    lstm: float

@app.post("/update_settings")
def update_settings(settings: Settings):
    current_settings["conf"] = settings.conf
    current_settings["lstm"] = settings.lstm
    detector.conf_threshold = settings.conf
    detector.lstm_threshold = settings.lstm
    print(f"üîÑ Updated: Conf={settings.conf}, LSTM={settings.lstm}")
    return {"status": "updated"}

@app.get("/status")
def get_status():
    return {
        "fall_detected": current_settings["fall_detected_now"],
        "is_running": True
    }

@app.get("/gallery")
def get_gallery(video_name: str):
    """API tr·∫£ v·ªÅ ·∫£nh c·ªßa ri√™ng video ƒë√≥"""
    specific_dir = os.path.join(SNAPSHOT_DIR, video_name)
    if not os.path.exists(specific_dir):
        return {"images": []}
    
    # L·∫•y danh s√°ch ·∫£nh, s·∫Øp x·∫øp m·ªõi nh·∫•t l√™n ƒë·∫ßu
    files = sorted(glob.glob(os.path.join(specific_dir, "*.jpg")), key=os.path.getmtime, reverse=True)
    
    # Tr·∫£ v·ªÅ ƒë∆∞·ªùng d·∫´n t∆∞∆°ng ƒë·ªëi: video_name/anh.jpg
    # Ch·ªâ l·∫•y 4 ·∫£nh m·ªõi nh·∫•t ƒë·ªÉ Dashboard ƒë·ª° lag
    rel_paths = [os.path.join(video_name, os.path.basename(f)).replace("\\", "/") for f in files[:4]]
    return {"images": rel_paths}

# --- LOGIC X·ª¨ L√ù VIDEO & BEST SHOT ---
def generate_frames(video_path):
    cap = cv2.VideoCapture(video_path)
    
    # 1. T·∫°o th∆∞ m·ª•c l∆∞u ·∫£nh ri√™ng cho video n√†y
    video_filename = os.path.basename(video_path)
    video_name_only = os.path.splitext(video_filename)[0]
    save_path = os.path.join(SNAPSHOT_DIR, video_name_only)
    if not os.path.exists(save_path): os.makedirs(save_path)

    # 2. Bi·∫øn theo d√µi logic "Best Shot"
    best_frame = None       
    max_score = 0.0         
    is_falling_sequence = False 

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret: break
        
        # Resize nh·∫π 
        frame = cv2.resize(frame, (640, 480))
        
        # --- G·ªåI AI ---
        # Nh·∫≠n v·ªÅ: Frame ƒë√£ v·∫Ω, s·ªë ng∆∞·ªùi ng√£, v√† ƒêI·ªÇM S·ªê (score)
        processed_frame, fall_count, score = detector.process_frame(frame)
        
        # C·∫≠p nh·∫≠t tr·∫°ng th√°i global cho Dashboard bi·∫øt ngay l·∫≠p t·ª©c
        current_settings["fall_detected_now"] = (fall_count > 0)

        # --- LOGIC T√åM ·∫¢NH T·ªêT NH·∫§T (BEST SHOT) ---
        if fall_count > 0:
            # A. ƒêANG TRONG QU√Å TR√åNH NG√É
            is_falling_sequence = True
            
            # N·∫øu khung h√¨nh n√†y r√µ h∆°n (score cao h∆°n) -> L∆∞u t·∫°m v√†o RAM
            if score >= max_score:
                max_score = score
                best_frame = processed_frame.copy() 
            
        else:
            # B. H·∫æT NG√É (Ho·∫∑c ng∆∞·ªùi v·ª´a ƒë·ª©ng d·∫≠y / chuy·ªÉn c·∫£nh)
            if is_falling_sequence:
                # K·∫øt th√∫c s·ª± ki·ªán -> L∆ØU ·∫¢NH T·ªêT NH·∫§T xu√¥ng ·ªï c·ª©ng
                if best_frame is not None:
                    timestamp = int(time.time())
                    filename = f"fall_{int(max_score*100)}conf_{timestamp}.jpg"
                    full_path = os.path.join(save_path, filename)
                    
                    cv2.imwrite(full_path, best_frame)
                    print(f"üì∏ Saved Evidence: {full_path} (Score: {max_score:.2f})")
                
                # Reset bi·∫øn ƒë·ªÉ ch·ªù c√∫ ng√£ ti·∫øp theo
                best_frame = None
                max_score = 0.0
                is_falling_sequence = False

        # Encode frame g·ª≠i v·ªÅ Client
        ret, buffer = cv2.imencode('.jpg', processed_frame)
        frame_bytes = buffer.tobytes()
        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
    
    cap.release()

@app.get("/video_feed")
def video_feed(video_path: str):
    return StreamingResponse(
        generate_frames(video_path), 
        media_type="multipart/x-mixed-replace; boundary=frame"
    )

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)