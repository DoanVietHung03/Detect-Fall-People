import cv2
import numpy as np
import os
import math
import time
import torch
from collections import deque
from ultralytics import YOLO
from supervision import ByteTrack, Detections, BoxAnnotator, LabelAnnotator, ColorPalette, Color
import onnxruntime as ort
from onnxruntime import SessionOptions # Import thÃªm Ä‘á»ƒ config log

from config import DEVICE

# --- CLASS HELPER: SOFTMAX (NUMPY) ---
def softmax(x):
    """TÃ­nh Softmax trÃªn Numpy Array Ä‘á»ƒ ra xÃ¡c suáº¥t %"""
    e_x = np.exp(x - np.max(x, axis=1, keepdims=True))
    return e_x / e_x.sum(axis=1, keepdims=True)

# --- CLASS HYBRID DETECTOR ---
class FallDetector:
    def __init__(self, model_pose='weights/yolo11s-pose.onnx', model_onnx='weights/gru_fall_model.onnx', conf_threshold=0.7):
        self.conf_threshold = conf_threshold
        self.device = torch.device(DEVICE)

        # 1. LOAD YOLO (POSE)
        print(f"Loading YOLO ({model_pose})...")
        # task='pose' giÃºp Ä‘á»‹nh hÃ¬nh output chuáº©n ngay cáº£ khi metadata ONNX thiáº¿u
        self.pose_model = YOLO(model_pose, task='pose') 
        
        # 2. LOAD ONNX (CLASSIFIER)
        print(f"ðŸš€ Loading ONNX Model ({model_onnx})...")
        if not os.path.exists(model_onnx):
            print(f"âŒ ERROR: KhÃ´ng tÃ¬m tháº¥y file ONNX táº¡i: {model_onnx}")
        
        # Cáº¥u hÃ¬nh Ä‘á»ƒ táº¯t cáº£nh bÃ¡o "Memcpy nodes"
        sess_options = SessionOptions()
        sess_options.log_severity_level = 3  # 0:Verbose, 1:Info, 2:Warning, 3:Error

        # Tá»± Ä‘á»™ng chá»n Provider (Æ¯u tiÃªn GPU)
        providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']
        try:
            self.ort_session = ort.InferenceSession(model_onnx, sess_options=sess_options, providers=providers)
            print(f"âœ… ONNX Session loaded with providers: {self.ort_session.get_providers()}")
        except Exception as e:
            print(f"âš ï¸ GPU Error, falling back to CPU: {e}")
            self.ort_session = ort.InferenceSession(model_onnx, sess_options=sess_options, providers=['CPUExecutionProvider'])

        self.input_name = self.ort_session.get_inputs()[0].name

        # 3. TRACKER CONFIG (Tá»‘i Æ°u cho viá»‡c ngÃ£)
        # TÄƒng lost_track_buffer lÃªn 60 (2 giÃ¢y) Ä‘á»ƒ giá»¯ ID lÃ¢u hÆ¡n khi bá»‹ khuáº¥t/biáº¿n dáº¡ng
        self.tracker = ByteTrack(track_activation_threshold=0.2, lost_track_buffer=90, frame_rate=30)

        # 4. ANNOTATORS
        self.box_annotator_green = BoxAnnotator(color=ColorPalette([Color.GREEN]), thickness=1)
        self.label_annotator_green = LabelAnnotator(color=ColorPalette([Color.GREEN]), text_color=Color.BLACK, text_scale=0.5)

        self.box_annotator_yellow = BoxAnnotator(color=ColorPalette([Color.YELLOW]), thickness=1)
        self.label_annotator_yellow = LabelAnnotator(color=ColorPalette([Color.YELLOW]), text_color=Color.BLACK, text_scale=0.5)

        self.box_annotator_red = BoxAnnotator(color=ColorPalette([Color.RED]), thickness=1)
        self.label_annotator_red = LabelAnnotator(color=ColorPalette([Color.RED]), text_color=Color.WHITE, text_scale=0.5)

        # 5. MEMORY & STATE
        self.SEQUENCE_LENGTH = 30
        self.MEMORY_TTL = 3.0        
        
        self.track_history = {}      # {id: deque([...])}
        self.last_valid_pose = {}    # {id: normalized_kps}
        self.track_last_seen = {}    # {id: timestamp}
        self.track_last_box = {}     # {id: [x1, y1, x2, y2]} -> LÆ°u vá»‹ trÃ­ cuá»‘i cÃ¹ng Ä‘á»ƒ Re-ID
        
        # Buffer cho tÃ­nh nÄƒng Merge Track (Re-ID logic)
        self.lost_tracks_buffer = {} # {id: {"box": box, "history": deque, "time": t}}
        self.MERGE_DIST_THRESHOLD = 150 # Pixel (Cháº¥p nháº­n di chuyá»ƒn 1 Ä‘oáº¡n khi ngÃ£)
        self.MERGE_TIME_THRESHOLD = 1.5 # GiÃ¢y

        # Business Logic
        self.fall_start_times = {}
        self.CONFIRM_DELAY = 1.0
        self.safe_zones = []

    def set_safe_zones(self, zones):
        self.safe_zones = zones

    # ================== HELPER FUNCTIONS ===================
    def calculate_aspect_ratio(self, box):
        w = box[2] - box[0]
        h = box[3] - box[1]
        return w / h if h > 0 else 0

    def calculate_spine_angle(self, kp):
        if len(kp) < 13: return None
        if (kp[5][2] < 0.3 or kp[6][2] < 0.3 or kp[11][2] < 0.3 or kp[12][2] < 0.3): return None 
        shoulder_x = (kp[5][0] + kp[6][0]) / 2
        shoulder_y = (kp[5][1] + kp[6][1]) / 2
        hip_x = (kp[11][0] + kp[12][0]) / 2
        hip_y = (kp[11][1] + kp[12][1]) / 2
        dx = abs(shoulder_x - hip_x)
        dy = abs(shoulder_y - hip_y)
        if dy == 0: return 0.0
        return math.degrees(math.atan2(dy, dx))

    def check_legs_standing(self, kp):
        has_left = (kp[15][2] > 0.3)
        has_right = (kp[16][2] > 0.3)
        if not has_left and not has_right: return False 
        hip_x = (kp[11][0] + kp[12][0]) / 2
        hip_y = (kp[11][1] + kp[12][1]) / 2
        ankle_x, ankle_y, c = 0, 0, 0
        if has_left: ankle_x += kp[15][0]; ankle_y += kp[15][1]; c += 1
        if has_right: ankle_x += kp[16][0]; ankle_y += kp[16][1]; c += 1
        if c == 0: return False
        dx = abs(hip_x - (ankle_x/c))
        dy = abs(hip_y - (ankle_y/c))
        angle = math.degrees(math.atan2(dy, dx))
        return angle > 45.0 

    def check_head_high(self, kp, box_ymin, box_ymax):
        head_y = []
        for i in range(5): 
            if kp[i][2] > 0.3: head_y.append(kp[i][1])
        if not head_y: return False
        avg_head_y = sum(head_y) / len(head_y)
        box_h = box_ymax - box_ymin
        return (avg_head_y - box_ymin) / box_h < 0.3

    def normalize_keypoints(self, keypoints, box):
        x1, y1, x2, y2 = box
        w = max(x2 - x1, 1e-6)
        h = max(y2 - y1, 1e-6)
        cx, cy = (x1 + x2) / 2, (y1 + y2) / 2
        normalized = []
        for kp in keypoints:
            normalized.extend([(kp[0] - cx)/w, (kp[1] - cy)/h])
        return normalized

    def is_in_safe_zone(self, box):
        if not self.safe_zones: return False
        cx = int((box[0] + box[2]) / 2)
        cy = int((box[1] + box[3]) / 2) 
        center_point = (cx, cy)
        for zone in self.safe_zones:
            if cv2.pointPolygonTest(zone, center_point, False) >= 0: return True
        return False

    def try_merge_tracks(self, new_id, new_box, current_time):
        """Logic tÃ¬m track cÅ© Ä‘á»ƒ ná»‘i vÃ o track má»›i"""
        best_match_id = None
        min_dist = float('inf')
        new_center = ((new_box[0]+new_box[2])/2, (new_box[1]+new_box[3])/2)

        # Lá»c danh sÃ¡ch háº¿t háº¡n
        expired = []
        for old_id, data in self.lost_tracks_buffer.items():
            if current_time - data["time"] > self.MERGE_TIME_THRESHOLD:
                expired.append(old_id)
                continue
            
            old_box = data["box"]
            old_center = ((old_box[0]+old_box[2])/2, (old_box[1]+old_box[3])/2)
            dist = np.hypot(new_center[0]-old_center[0], new_center[1]-old_center[1])

            if dist < self.MERGE_DIST_THRESHOLD:
                if dist < min_dist:
                    min_dist = dist
                    best_match_id = old_id
        
        for eid in expired: del self.lost_tracks_buffer[eid]
        return best_match_id
    
    def calculate_visibility(self, kps):
        """Tráº£ vá» % sá»‘ Ä‘iá»ƒm khá»›p nhÃ¬n tháº¥y rÃµ"""
        if kps is None or len(kps) == 0: return 0.0
        visible_count = sum(1 for p in kps if p[2] > 0.4) # Conf > 0.4 coi lÃ  tháº¥y
        return visible_count / 17.0

    # ================== PROCESS FRAME ==================
    def process_frame(self, frame):
        current_time = time.time()
        
        # 1. Detect YOLO
        # LÆ°u Ã½: Khi dÃ¹ng multiprocessing, device Ä‘Æ°á»£c tá»± Ä‘á»™ng handle bá»Ÿi Ultralytics/ONNX
        results = self.pose_model(frame, verbose=False, conf=self.conf_threshold, classes=[0])[0]
        detections = Detections.from_ultralytics(results)
        
        # 2. Tracking
        detections = self.tracker.update_with_detections(detections)

        yolo_boxes = results.boxes.xyxy.cpu().numpy() if results.boxes else []
        yolo_kps = results.keypoints.data.cpu().numpy() if results.keypoints else []

        # --- RE-ID LOGIC: QUáº¢N LÃ TRACK Máº¤T ---
        # TÃ¬m nhá»¯ng ID vá»«a biáº¿n máº¥t trong frame nÃ y
        active_ids = set(detections.tracker_id) if detections.tracker_id is not None else set()
        existing_ids = set(self.track_history.keys())
        lost_ids = existing_ids - active_ids
        
        for lid in lost_ids:
            # LÆ°u vÃ o buffer táº¡m Ä‘á»ƒ chá» há»“i sinh
            if lid in self.track_last_box and len(self.track_history[lid]) > 5:
                self.lost_tracks_buffer[lid] = {
                    "box": self.track_last_box[lid],
                    "history": self.track_history[lid],
                    "time": current_time
                }
            # XÃ³a khá»i bá»™ nhá»› chÃ­nh
            del self.track_history[lid]
            if lid in self.track_last_seen: del self.track_last_seen[lid]

        # Chuáº©n bá»‹ Batch Input cho LSTM
        lstm_batch_input = []
        lstm_batch_ids = []
        analysis_results = {} 

        # --- VÃ’NG Láº¶P 1: THU THáº¬P & Xá»¬ LÃ ID ---
        for i, (track_box, track_id) in enumerate(zip(detections.xyxy, detections.tracker_id)):
            self.track_last_seen[track_id] = current_time
            self.track_last_box[track_id] = track_box

            # Xá»­ lÃ½ ID má»›i: Thá»­ tÃ¬m láº¡i track cÅ© (Merge)
            if track_id not in self.track_history:
                merged_old_id = self.try_merge_tracks(track_id, track_box, current_time)
                if merged_old_id:
                    # print(f"Merge: {merged_old_id} -> {track_id}")
                    self.track_history[track_id] = self.lost_tracks_buffer[merged_old_id]["history"]
                    del self.lost_tracks_buffer[merged_old_id] # XÃ³a khá»i buffer chá»
                    
                    # Náº¿u track cÅ© Ä‘ang Ä‘áº¿m giá» ngÃ£ -> Chuyá»ƒn sang track má»›i
                    if merged_old_id in self.fall_start_times:
                        self.fall_start_times[track_id] = self.fall_start_times[merged_old_id]
                        del self.fall_start_times[merged_old_id]
                else:
                    self.track_history[track_id] = deque(maxlen=self.SEQUENCE_LENGTH)

            # Match Keypoints
            matched_kps = None
            min_dist = 200
            track_center = ((track_box[0]+track_box[2])/2, (track_box[1]+track_box[3])/2)
            
            if len(yolo_kps) > 0:
                for box_orig, kps_orig in zip(yolo_boxes, yolo_kps):
                    orig_ctr = ((box_orig[0]+box_orig[2])/2, (box_orig[1]+box_orig[3])/2)
                    dist = np.hypot(track_center[0]-orig_ctr[0], track_center[1]-orig_ctr[1])
                    if dist < min_dist:
                        min_dist = dist
                        matched_kps = kps_orig

            # Normalize Pose
            norm_kps = [0.0] * 34
            has_pose = False
            
            if matched_kps is not None:
                has_pose = True
                # Chuáº©n hÃ³a hiá»‡n táº¡i
                current_norm_kps = self.normalize_keypoints(matched_kps, track_box)
                
                # Logic: Náº¿u Ä‘iá»ƒm nÃ o cÃ³ Ä‘á»™ tin cáº­y tháº¥p (bá»‹ che), láº¥y tá»« quÃ¡ khá»© Ä‘áº¯p vÃ o
                if track_id in self.last_valid_pose:
                    last_kps = self.last_valid_pose[track_id]
                    final_kps = []
                    for i in range(17): # 17 Ä‘iá»ƒm khá»›p
                        # Index trong vector pháº³ng: x=2*i, y=2*i+1
                        idx_x, idx_y = 2*i, 2*i+1
                        conf = matched_kps[i][2] # Äá»™ tin cáº­y tá»« YOLO
                        
                        if conf < 0.3: # Bá»‹ che hoáº·c má»
                            # Láº¥y toáº¡ Ä‘á»™ cÅ©
                            final_kps.extend([last_kps[idx_x], last_kps[idx_y]])
                        else:
                            # Láº¥y toáº¡ Ä‘á»™ má»›i
                            final_kps.extend([current_norm_kps[idx_x], current_norm_kps[idx_y]])
                    norm_kps = final_kps
                else:
                    norm_kps = current_norm_kps

                # Cáº­p nháº­t láº¡i bá»™ nhá»› (LÆ°u cÃ¡i Ä‘Ã£ fill Ä‘á»ƒ dÃ¹ng cho frame sau)
                self.last_valid_pose[track_id] = norm_kps
            
            elif track_id in self.last_valid_pose:
                # Máº¥t toÃ n bá»™ Pose -> DÃ¹ng láº¡i toÃ n bá»™ Pose cÅ©
                norm_kps = self.last_valid_pose[track_id]

            self.track_history[track_id].append(norm_kps)

            if len(self.track_history[track_id]) == self.SEQUENCE_LENGTH:
                lstm_batch_input.append(list(self.track_history[track_id]))
                lstm_batch_ids.append(track_id)

            analysis_results[track_id] = {
                "box": track_box,
                "kps": matched_kps,
                "has_pose": has_pose,
                "lstm_prob": 0.0,
                "status": "NORMAL"
            }

        # --- VÃ’NG Láº¶P 2: BATCH INFERENCE ONNX ---
        if len(lstm_batch_input) > 0:
            input_data = np.array(lstm_batch_input, dtype=np.float32)
            ort_inputs = {self.input_name: input_data}
            ort_outs = self.ort_session.run(None, ort_inputs)
            
            probs = softmax(ort_outs[0])
            fall_probs = probs[:, 1] # Class 1 = Fall

            for idx, tid in enumerate(lstm_batch_ids):
                analysis_results[tid]["lstm_prob"] = float(fall_probs[idx])

        # --- VÃ’NG Láº¶P 3: LOGIC & VISUALIZATION ---
        final_fall_count = 0
        max_score = 0.0
        
        idx_green, labels_green = [], []
        idx_yellow, labels_yellow = [], []
        idx_red, labels_red = [], []
        
        for i, (track_box, track_id) in enumerate(zip(detections.xyxy, detections.tracker_id)):
            data = analysis_results[track_id]
            ai_prob = data["lstm_prob"]
            kps = data["kps"]
            has_pose = data["has_pose"]
            aspect_ratio = self.calculate_aspect_ratio(track_box)
            
            visibility = self.calculate_visibility(kps) if has_pose else 0.0
            is_potential_fall = False
            reason = "OK"

            # --- ADAPTIVE LOGIC ---
            
            # CASE 1: NHÃŒN THáº¤Y RÃ• (> 60% cÆ¡ thá»ƒ) -> DÃ¹ng luáº­t cháº·t cháº½ nhÆ° cÅ©
            if visibility > 0.6:
                spine_angle = self.calculate_spine_angle(kps) or 90
                legs_standing = self.check_legs_standing(kps)
                
                # Náº¿u AI cá»±c cao thÃ¬ bÃ¡o luÃ´n (báº¥t cháº¥p gÃ³c)
                if ai_prob > 0.85:
                    is_potential_fall = True
                    reason = f"Clear_AI:{ai_prob:.2f}"
                # Náº¿u AI khÃ¡ + GÃ³c nghiÃªng
                elif ai_prob > 0.6 and spine_angle < 60:
                     if not legs_standing:
                        is_potential_fall = True
                        reason = f"Clear_Hybrid"
                # Náº¿u náº±m báº¹p gÃ­
                elif spine_angle < 20:
                    is_potential_fall = True
                    reason = "Clear_Flat"

            # CASE 2: Bá»Š CHE KHUáº¤T (< 60% cÆ¡ thá»ƒ)
            # Khi bá»‹ che, YOLO hay báº¯t sai chÃ¢n tay -> GÃ³c Spine sai -> Bá» qua check gÃ³c
            elif visibility > 0.2: 
                # Chá»‰ cáº§n AI nghi ngá» + Há»™p dáº¹t (Aspect Ratio)
                # Aspect Ratio: W/H. NgÆ°á»i Ä‘á»©ng ~0.5. NgÆ°á»i ngÃ£/ngá»“i > 1.0
                if ai_prob > 0.55: # Giáº£m ngÆ°á»¡ng AI xuá»‘ng
                    if aspect_ratio > 0.9: # Há»™p báº¯t Ä‘áº§u bÃ¨ ra
                        is_potential_fall = True
                        reason = f"Obscured_AI:{ai_prob:.2f}"
            
            # CASE 3: Máº¤T Háº¾T POSE HOáº¶C CHE Gáº¦N Háº¾T -> Chá»‰ dÃ¹ng Box
            else:
                if aspect_ratio > 1.2 and ai_prob > 0.5:
                    is_potential_fall = True
                    reason = "BoxOnly"

            if is_potential_fall and self.is_in_safe_zone(track_box):
                is_potential_fall = False
                reason = "Safe"

            # State Machine
            if is_potential_fall:
                if track_id not in self.fall_start_times:
                    self.fall_start_times[track_id] = current_time
                    idx_yellow.append(i)
                    labels_yellow.append(f"Wait... {reason}")
                else:
                    elapsed = current_time - self.fall_start_times[track_id]
                    if elapsed > self.CONFIRM_DELAY:
                        final_fall_count += 1
                        if ai_prob > max_score: max_score = ai_prob
                        idx_red.append(i)
                        labels_red.append(f"FALL! {reason}")
                    else:
                        idx_yellow.append(i)
                        labels_yellow.append(f"Wait {self.CONFIRM_DELAY - elapsed:.1f}s")
            else:
                if track_id in self.fall_start_times: del self.fall_start_times[track_id]
                idx_green.append(i)
                labels_green.append(f"ID:{track_id}")

        # CLEANUP
        cleanup_ids = []
        for tid, last_seen in self.track_last_seen.items():
            if current_time - last_seen > self.MEMORY_TTL: cleanup_ids.append(tid)
        for tid in cleanup_ids:
            if tid in self.track_history: del self.track_history[tid]
            if tid in self.last_valid_pose: del self.last_valid_pose[tid]
            if tid in self.fall_start_times: del self.fall_start_times[tid]
            if tid in self.track_last_seen: del self.track_last_seen[tid]
            if tid in self.track_last_box: del self.track_last_box[tid]

        # DRAW
        ann = frame.copy()
        if self.safe_zones: cv2.polylines(ann, self.safe_zones, True, (255, 200, 0), 2)
        
        if idx_green:
            det = detections[np.array(idx_green)]
            ann = self.box_annotator_green.annotate(ann, det)
            ann = self.label_annotator_green.annotate(ann, det, labels=labels_green)
        if idx_yellow:
            det = detections[np.array(idx_yellow)]
            ann = self.box_annotator_yellow.annotate(ann, det)
            ann = self.label_annotator_yellow.annotate(ann, det, labels=labels_yellow)
        if idx_red:
            det = detections[np.array(idx_red)]
            ann = self.box_annotator_red.annotate(ann, det)
            ann = self.label_annotator_red.annotate(ann, det, labels=labels_red)

        return ann, final_fall_count, max_score