import onnx
from onnxconverter_common import float16

def convert_to_fp16(input_model_path, output_model_path):
    print(f"ğŸ”„ Äang Ä‘á»c model: {input_model_path}...")
    try:
        model = onnx.load(input_model_path)
    except FileNotFoundError:
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y file: {input_model_path}")
        return

    print("âš™ï¸  Äang chuyá»ƒn Ä‘á»•i sang FP16...")
    # keep_io_types=True: Giá»¯ nguyÃªn kiá»ƒu dá»¯ liá»‡u Ä‘áº§u vÃ o/Ä‘áº§u ra lÃ  Float32 
    # Ä‘á»ƒ khÃ´ng pháº£i sá»­a code pre-processing trong inference.py
    fp16_model = float16.convert_float_to_float16(model, keep_io_types=True)

    print(f"ğŸ’¾ Äang lÆ°u model má»›i: {output_model_path}...")
    onnx.save(fp16_model, output_model_path)
    print("âœ… HoÃ n táº¥t!")

if __name__ == "__main__":
    # 1. Convert Model PhÃ¢n loáº¡i hÃ nh vi (GRU/LSTM)
    convert_to_fp16("../weights/gru_fall_model.onnx", "../weights/gru_fall_model_fp16.onnx")

    # 2. (TÃ¹y chá»n) Convert Model YOLO Pose náº¿u báº¡n Ä‘ang dÃ¹ng file ONNX
    # LÆ°u Ã½: Náº¿u báº¡n export tá»« Ultralytics, tá»‘t nháº¥t nÃªn dÃ¹ng lá»‡nh export cá»§a há»:
    # yolo export model=yolo11s-pose.pt format=onnx half=True
    # NhÆ°ng náº¿u báº¡n chá»‰ cÃ³ file onnx, cÃ³ thá»ƒ thá»­ convert báº±ng script nÃ y:
    # convert_to_fp16("weights/yolo11s-pose.onnx", "weights/yolo11s-pose_fp16.onnx")