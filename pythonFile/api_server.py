# api_server.py
from fastapi import FastAPI
from fastapi.responses import StreamingResponse
from fastapi.staticfiles import StaticFiles
import cv2
import uvicorn
import glob
import time
from pydantic import BaseModel
from typing import List
import os
import sys

# L·∫•y ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c ch·ª©a file api_server.py v√† th√™m v√†o sys.path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from inference import FallDetector

app = FastAPI()

# --- C·∫§U H√åNH ---
SNAPSHOT_DIR = "../snapshots"
if not os.path.exists(SNAPSHOT_DIR): os.makedirs(SNAPSHOT_DIR)

# Mount th∆∞ m·ª•c ·∫£nh ƒë·ªÉ Dashboard c√≥ th·ªÉ xem qua URL
app.mount("/snapshots", StaticFiles(directory=SNAPSHOT_DIR), name="snapshots")

# --- GLOBAL STATE ---
current_settings = {
    "conf": 0.7,
    "lstm": 0.7,
    "fall_detected_now": False,
    "is_active": False
}

# Model d·ªØ li·ªáu cho v√πng an to√†n
class ZoneConfig(BaseModel):
    zones: List[List[List[int]]]

# Kh·ªüi t·∫°o model
print("‚è≥ ƒêang t·∫£i model AI...")
detector = FallDetector(
    model_pose='../weights/yolo11m-pose.pt',
    model_lstm='../weights/lstm_fall_model.pth'
)
print("‚úÖ AI ƒë√£ s·∫µn s√†ng!")

class Settings(BaseModel):
    conf: float
    lstm: float
    
@app.post("/update_zones")
def update_zones(config: ZoneConfig):
    try:
        new_zones = []
        for polygon in config.zones:
            pts = np.array(polygon, np.int32)
            new_zones.append(pts)
        detector.set_safe_zones(new_zones)
        return {"status": "success", "count": len(new_zones)}
    except Exception as e:
        return {"status": "error", "message": str(e)}

@app.post("/update_settings")
def update_settings(settings: Settings):
    current_settings["conf"] = settings.conf
    current_settings["lstm"] = settings.lstm
    detector.conf_threshold = settings.conf
    detector.lstm_threshold = settings.lstm
    print(f"üîÑ Updated: Conf={settings.conf}, LSTM={settings.lstm}")
    return {"status": "updated"}

@app.get("/status")
def get_status():
    return {
        "fall_detected": current_settings["fall_detected_now"],
        "is_active": current_settings["is_active"]
    }

@app.get("/gallery")
def get_gallery(video_name: str):
    specific_dir = os.path.join(SNAPSHOT_DIR, video_name)
    if not os.path.exists(specific_dir):
        return {"images": []}
    
    # L·∫•y danh s√°ch ·∫£nh, s·∫Øp x·∫øp m·ªõi nh·∫•t l√™n ƒë·∫ßu (theo th·ªùi gian s·ª≠a ƒë·ªïi)
    files = sorted(glob.glob(os.path.join(specific_dir, "*.jpg")), key=os.path.getmtime, reverse=True)
    
    rel_paths = [os.path.join(video_name, os.path.basename(f)).replace("\\", "/") for f in files[:6]]
    return {"images": rel_paths}

# --- H√ÄM D·ªåN D·∫∏P ·∫¢NH C≈® ---
def cleanup_old_files(folder_path, max_files=50):
    """X√≥a b·ªõt ·∫£nh c≈© n·∫øu v∆∞·ª£t qu√° s·ªë l∆∞·ª£ng cho ph√©p"""
    try:
        files = glob.glob(os.path.join(folder_path, "*.jpg"))
        if len(files) > max_files:
            # S·∫Øp x·∫øp theo th·ªùi gian (c≈© nh·∫•t ƒë·ª©ng ƒë·∫ßu)
            files.sort(key=os.path.getmtime)
            # S·ªë l∆∞·ª£ng c·∫ßn x√≥a
            num_to_delete = len(files) - max_files
            for f in files[:num_to_delete]:
                os.remove(f)
            print(f"üßπ Cleaned up {num_to_delete} old images.")
    except Exception as e:
        print(f"Cleanup error: {e}")

# --- H√ÄM L∆ØU ·∫¢NH ---
def save_evidence(frame, score, folder_path, prefix="fall"):
    if frame is None: return
    timestamp = int(time.time())
    # T·∫°o t√™n file bao g·ªìm score ƒë·ªÉ d·ªÖ debug
    filename = f"{prefix}_{int(score*100)}conf_{timestamp}.jpg"
    full_path = os.path.join(folder_path, filename)
    cv2.imwrite(full_path, frame)
    print(f"üì∏ Saved Evidence: {full_path} (Score: {score:.2f})")
    cleanup_old_files(folder_path, max_files=100)

# --- LOGIC X·ª¨ L√ù VIDEO ---
def generate_frames(video_path):
    current_settings["is_active"] = True
    cap = cv2.VideoCapture(video_path)
    
    if "rtsp://" in video_path:
        # L·∫•y ph·∫ßn cu·ªëi c·ªßa link (vd: cam_coffee) l√†m t√™n th∆∞ m·ª•c
        video_name_only = video_path.split("/")[-1]
    else:
        # Logic c≈© cho file
        video_filename = os.path.basename(video_path)
        video_name_only = os.path.splitext(video_filename)[0]
        
    save_path = os.path.join(SNAPSHOT_DIR, video_name_only)
    if not os.path.exists(save_path): os.makedirs(save_path)

    best_frame = None       
    max_score = 0.0         
    is_falling_sequence = False 
    
    # Bi·∫øn ƒë·ªÉ ki·ªÉm so√°t vi·ªác l∆∞u (tr√°nh l∆∞u qu√° nhi·ªÅu tr√πng l·∫∑p)
    last_saved_time = 0 

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret: 
            break # Video k·∫øt th√∫c
        
        # Resize nh·∫π 
        frame = cv2.resize(frame, (640, 480))
        
        # --- G·ªåI AI ---
        processed_frame, fall_count, score = detector.process_frame(frame)
        current_settings["fall_detected_now"] = (fall_count > 0)

        # --- LOGIC BEST SHOT (ƒê√É S·ª¨A) ---
        if fall_count > 0:
            current_time = time.time()
            
            # N·∫øu l√† b·∫Øt ƒë·∫ßu sequence m·ªõi
            if not is_falling_sequence:
                is_falling_sequence = True
                max_score = 0.0
                best_frame = None
                frames_saved_in_sequence = 0
                print("‚ö†Ô∏è Fall Started - Tracking best shot...")

            # C·∫≠p nh·∫≠t khung h√¨nh t·ªët nh·∫•t n·∫øu ƒëi·ªÉm cao h∆°n
            if score >= max_score:
                max_score = score
                best_frame = processed_frame.copy()
                
                # OPTIONAL: L∆∞u ngay l·∫≠p t·ª©c n·∫øu score r·∫•t cao (>0.85) ƒë·ªÉ hi·ªÉn th·ªã ngay tr√™n Dashboard
                # Thay v√¨ ch·ªù ng√£ xong m·ªõi hi·ªán.
                if max_score > 0.85 and (current_time - last_saved_time > 5.0) and frames_saved_in_sequence < 3:
                    save_evidence(best_frame, max_score, save_path)
                    last_saved_time = current_time
                    frames_saved_in_sequence += 1

        else:
            # Ng∆∞·ªùi ƒë√£ ƒë·ª©ng d·∫≠y ho·∫∑c h·∫øt ng√£
            if is_falling_sequence:
                print("‚úÖ Fall Sequence Ended. Saving final best shot.")
                # L∆∞u c√°i t·ªët nh·∫•t c√≤n l·∫°i trong sequence
                save_evidence(best_frame, max_score, save_path)
                
                # Reset
                is_falling_sequence = False
                best_frame = None
                max_score = 0.0

        # Encode frame g·ª≠i v·ªÅ Client
        ret, buffer = cv2.imencode('.jpg', processed_frame)
        frame_bytes = buffer.tobytes()
        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
    
    # --- QUAN TR·ªåNG: X·ª¨ L√ù KHI LOOP K·∫æT TH√öC (Video h·∫øt) ---
    # N·∫øu video h·∫øt m√† v·∫´n ƒëang trong tr·∫°ng th√°i ng√£ -> L∆ØU NGAY
    current_settings["is_active"] = False
    if is_falling_sequence and best_frame is not None:
        print("‚èπÔ∏è Video Ended during fall. Saving pending evidence.")
        save_evidence(best_frame, max_score, save_path)

    cap.release()

@app.get("/video_feed")
def video_feed(video_path: str):
    return StreamingResponse(
        generate_frames(video_path), 
        media_type="multipart/x-mixed-replace; boundary=frame"
    )

if __name__ == "__main__":
    import numpy as np # Import th√™m ·ªü ƒë√¢y n·∫øu ch∆∞a c√≥ global import
    uvicorn.run(app, host="0.0.0.0", port=8000)