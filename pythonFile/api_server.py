# api_server.py
import cv2
import uvicorn
import time
import os
import sys
import torch
import multiprocessing as mp # Import th∆∞ vi·ªán multiprocessing
from queue import Empty, Full # ƒê·ªÉ x·ª≠ l√Ω ngo·∫°i l·ªá queue

from typing import Dict
from contextlib import asynccontextmanager
from fastapi import FastAPI, Request
from fastapi.responses import StreamingResponse, HTMLResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates

# --- IMPORT MODULE ---
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from inference import FallDetector
from camera_loader import CameraStream  

# --- CONFIG ---
current_file_path = os.path.abspath(__file__)
current_dir = os.path.dirname(current_file_path)
project_root = os.path.dirname(current_dir)
SNAPSHOT_DIR = os.path.join(project_root, "snapshots")
if not os.path.exists(SNAPSHOT_DIR): os.makedirs(SNAPSHOT_DIR)

CAMERAS_CONFIG = {
    "cam_1": "rtsp://rtsp-server:8554/cam_1",
    "cam_2": "rtsp://rtsp-server:8554/cam_2",
    # Th√™m cam_3, cam_4... tho·∫£i m√°i
}

# --- PROCESS CLASS (Thay th·∫ø Thread Class c≈©) ---
class CameraProcess(mp.Process):
    def __init__(self, cam_id, rtsp_url, frame_queue, state_queue, command_event):
        super().__init__()
        self.cam_id = cam_id
        self.rtsp_url = rtsp_url
        self.frame_queue = frame_queue   # Queue ƒë·ªÉ g·ª≠i ·∫£nh v·ªÅ API (hi·ªÉn th·ªã)
        self.state_queue = state_queue   # Queue ƒë·ªÉ g·ª≠i tr·∫°ng th√°i (ng√£ hay kh√¥ng)
        self.command_event = command_event # Event ƒë·ªÉ b√°o d·ª´ng
        
        # CH√ö √ù: KH√îNG load model ·ªü ƒë√¢y (ƒë√¢y l√† Process Cha)

    def run(self):
        # --- ƒê√ÇY L√Ä PROCESS CON (CH·∫†Y ƒê·ªòC L·∫¨P) ---
        print(f"üöÄ [{self.cam_id}] Process Started. PID: {os.getpid()}")
        
        # 1. Load Model (Ch·ªâ load trong process con ƒë·ªÉ m·ªói con c√≥ CUDA context ri√™ng)
        weights_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "weights")
        path_pose = os.path.join(weights_dir, "yolo11s-pose.onnx") 
        path_onnx = os.path.join(weights_dir, "gru_fall_model.onnx")
        
        try:
            detector = FallDetector(model_pose=path_pose, model_onnx=path_onnx)
        except Exception as e:
            print(f"‚ùå [{self.cam_id}] AI Init Failed: {e}")
            return

        # 2. Kh·ªüi t·∫°o Camera Stream
        stream = CameraStream(self.rtsp_url, self.cam_id)
        stream.start()

        save_path = os.path.join(SNAPSHOT_DIR, self.cam_id)
        if not os.path.exists(save_path): os.makedirs(save_path)
        max_score_in_session = 0.0
        
        # Bi·∫øn local l∆∞u state ƒë·ªÉ kh√¥ng spam queue
        current_state = {"fall": False, "snapshot": None}

        while not self.command_event.is_set():
            status, frame = stream.read()
            if not status or frame is None:
                time.sleep(0.01)
                continue

            # Resize & Inference
            w = frame.shape[1] // 2
            h = frame.shape[0] // 2
            frame_resized = cv2.resize(frame, (w, h))

            processed_frame, fall_count, score = detector.process_frame(frame_resized)
            is_fall = (fall_count > 0)

            # Logic Snapshot (nh∆∞ c≈©)
            snapshot_url = current_state["snapshot"]
            if is_fall:
                if score > max_score_in_session or score > 0.8:
                    max_score_in_session = score
                    filename = f"{self.cam_id}_fall_{int(score*100)}.jpg"
                    cv2.imwrite(os.path.join(save_path, filename), processed_frame)
                    snapshot_url = f"/snapshots/{self.cam_id}/{filename}?t={int(time.time())}"
            else:
                if max_score_in_session > 0: max_score_in_session = 0.0
            
            # --- G·ª¨I D·ªÆ LI·ªÜU V·ªÄ API (QUAN TR·ªåNG) ---
            
            # 1. G·ª≠i Frame (D√πng put_nowait v√† try-except ƒë·ªÉ kh√¥ng b·ªã block n·∫øu queue ƒë·∫ßy)
            # Encode JPG tr∆∞·ªõc khi g·ª≠i ƒë·ªÉ gi·∫£m dung l∆∞·ª£ng qua Queue (quan tr·ªçng cho performance)
            ret, buffer = cv2.imencode('.jpg', processed_frame)
            if ret:
                frame_bytes = buffer.tobytes()
                try:
                    # N·∫øu queue ƒë·∫ßy, l·∫•y c√°i c≈© ra v·ª©t ƒëi ƒë·ªÉ b·ªè c√°i m·ªõi v√†o (lu√¥n l·∫•y ·∫£nh m·ªõi nh·∫•t)
                    if self.frame_queue.full():
                        try: self.frame_queue.get_nowait()
                        except Empty: pass 
                    self.frame_queue.put_nowait(frame_bytes)
                except Full:
                    pass # Queue v·∫´n ƒë·∫ßy th√¨ b·ªè qua frame n√†y

            # 2. G·ª≠i State (Ch·ªâ g·ª≠i khi c√≥ thay ƒë·ªïi ho·∫∑c ƒë·ªãnh k·ª≥ ƒë·ªÉ ti·∫øt ki·ªám CPU)
            new_state = {"fall": is_fall, "snapshot": snapshot_url}
            if new_state != current_state or time.time() % 1.0 < 0.05: # G·ª≠i m·ªói 1s ho·∫∑c khi kh√°c bi·ªát
                try:
                    if self.state_queue.full():
                        try: self.state_queue.get_nowait()
                        except: pass
                    self.state_queue.put_nowait(new_state)
                    current_state = new_state
                except: pass

            # Gi·ªõi h·∫°n FPS AI (t√πy ch·ªânh)
            time.sleep(0.03) 
        
        # Cleanup
        stream.stop()
        print(f"üõë [{self.cam_id}] Process Stopped.")

# --- QU·∫¢N L√ù C√ÅC PROCESS ---
processes = {}
queues = {} # L∆∞u queue c·ªßa t·ª´ng cam: { "cam_1": {"frame": Q, "state": Q, "last_state_data": {}} }

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Set start method l√† 'spawn' ƒë·ªÉ an to√†n cho CUDA
    try:
        mp.set_start_method('spawn', force=True)
    except RuntimeError:
        pass # ƒê√£ set r·ªìi th√¨ th√¥i

    print("üöÄ Starting Camera Processes...")
    for cam_id, url in CAMERAS_CONFIG.items():
        # T·∫°o Queue v·ªõi maxsize=1 (Ch·ªâ gi·ªØ 1 frame/state m·ªõi nh·∫•t)
        frame_q = mp.Queue(maxsize=1)
        state_q = mp.Queue(maxsize=1)
        stop_event = mp.Event()

        p = CameraProcess(cam_id, url, frame_q, state_q, stop_event)
        p.start()
        
        processes[cam_id] = {"process": p, "stop_event": stop_event}
        queues[cam_id] = {"frame": frame_q, "state": state_q, "last_known_state": {"fall": False, "snapshot": None}}
    
    yield
    
    print("üõë Shutting down Camera Processes...")
    for cam_id, item in processes.items():
        item["stop_event"].set()
        item["process"].join(timeout=5)
        if item["process"].is_alive():
            item["process"].terminate()

app = FastAPI(lifespan=lifespan)
app.mount("/snapshots", StaticFiles(directory=SNAPSHOT_DIR), name="snapshots")
templates = Jinja2Templates(directory="pythonFile/templates")

# --- API ROUTES ---
@app.get("/", response_class=HTMLResponse)
async def read_root(request: Request):
    return templates.TemplateResponse("index.html", {"request": request, "cameras": CAMERAS_CONFIG})

@app.get("/api/updates")
def get_updates():
    # L·∫•y state m·ªõi nh·∫•t t·ª´ Queue (Non-blocking)
    results = {}
    for cam_id, item in queues.items():
        q = item["state"]
        try:
            # L·∫•y data m·ªõi n·∫øu c√≥
            while not q.empty():
                item["last_known_state"] = q.get_nowait()
        except Empty:
            pass
        results[cam_id] = item["last_known_state"]
    return results

def frame_generator(cam_id):
    if cam_id not in queues: return
    frame_q = queues[cam_id]["frame"]
    
    while True:
        try:
            # Timeout 1s ƒë·ªÉ tr√°nh v√≤ng l·∫∑p ch·∫øt n·∫øu process ch·∫øt
            frame_bytes = frame_q.get(timeout=1.0) 
            yield (b'--frame\r\nContent-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
        except Empty:
            # N·∫øu kh√¥ng c√≥ frame n√†o trong 1s (Camera m·∫•t k·∫øt n·ªëi ho·∫∑c l·ªói)
            # C√≥ th·ªÉ tr·∫£ v·ªÅ ·∫£nh placeholder ho·∫∑c ch·ªù ti·∫øp
            time.sleep(0.1)

@app.get("/video_feed")
def video_feed(cam_id: str):
    if cam_id not in CAMERAS_CONFIG: return HTMLResponse("Not Found", 404)
    return StreamingResponse(frame_generator(cam_id), media_type="multipart/x-mixed-replace; boundary=frame")

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)