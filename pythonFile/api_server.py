# api_server.py
from fastapi import FastAPI
from fastapi.responses import StreamingResponse
from fastapi.staticfiles import StaticFiles
import cv2
import uvicorn
import os
import glob
import time
from pydantic import BaseModel
from inference import FallDetector
from typing import List

app = FastAPI()

# --- C·∫§U H√åNH ---
SNAPSHOT_DIR = "../snapshots"
if not os.path.exists(SNAPSHOT_DIR): os.makedirs(SNAPSHOT_DIR)

# Mount th∆∞ m·ª•c ·∫£nh ƒë·ªÉ Dashboard c√≥ th·ªÉ xem qua URL
app.mount("/snapshots", StaticFiles(directory=SNAPSHOT_DIR), name="snapshots")

# --- GLOBAL STATE ---
current_settings = {
    "conf": 0.7,
    "lstm": 0.7,
    "fall_detected_now": False 
}

# Model d·ªØ li·ªáu cho v√πng an to√†n
class ZoneConfig(BaseModel):
    zones: List[List[List[int]]]

# Kh·ªüi t·∫°o model
print("‚è≥ ƒêang t·∫£i model AI...")
detector = FallDetector(
    model_pose='../weights/yolo11m-pose.pt',
    model_lstm='../weights/lstm_fall_model.pth'
)
print("‚úÖ AI ƒë√£ s·∫µn s√†ng!")

class Settings(BaseModel):
    conf: float
    lstm: float
    
@app.post("/update_zones")
def update_zones(config: ZoneConfig):
    try:
        new_zones = []
        for polygon in config.zones:
            pts = np.array(polygon, np.int32)
            new_zones.append(pts)
        detector.set_safe_zones(new_zones)
        return {"status": "success", "count": len(new_zones)}
    except Exception as e:
        return {"status": "error", "message": str(e)}

@app.post("/update_settings")
def update_settings(settings: Settings):
    current_settings["conf"] = settings.conf
    current_settings["lstm"] = settings.lstm
    detector.conf_threshold = settings.conf
    detector.lstm_threshold = settings.lstm
    print(f"üîÑ Updated: Conf={settings.conf}, LSTM={settings.lstm}")
    return {"status": "updated"}

@app.get("/status")
def get_status():
    return {
        "fall_detected": current_settings["fall_detected_now"]
    }

@app.get("/gallery")
def get_gallery(video_name: str):
    specific_dir = os.path.join(SNAPSHOT_DIR, video_name)
    if not os.path.exists(specific_dir):
        return {"images": []}
    
    # L·∫•y danh s√°ch ·∫£nh, s·∫Øp x·∫øp m·ªõi nh·∫•t l√™n ƒë·∫ßu (theo th·ªùi gian s·ª≠a ƒë·ªïi)
    files = sorted(glob.glob(os.path.join(specific_dir, "*.jpg")), key=os.path.getmtime, reverse=True)
    
    rel_paths = [os.path.join(video_name, os.path.basename(f)).replace("\\", "/") for f in files[:6]]
    return {"images": rel_paths}

# --- H√ÄM L∆ØU ·∫¢NH ---
def save_evidence(frame, score, folder_path, prefix="fall"):
    if frame is None: return
    timestamp = int(time.time())
    # T·∫°o t√™n file bao g·ªìm score ƒë·ªÉ d·ªÖ debug
    filename = f"{prefix}_{int(score*100)}conf_{timestamp}.jpg"
    full_path = os.path.join(folder_path, filename)
    cv2.imwrite(full_path, frame)
    print(f"üì∏ Saved Evidence: {full_path} (Score: {score:.2f})")

# --- LOGIC X·ª¨ L√ù VIDEO ---
def generate_frames(video_path):
    cap = cv2.VideoCapture(video_path)
    
    # 1. T·∫°o th∆∞ m·ª•c l∆∞u ·∫£nh ri√™ng cho video n√†y
    video_filename = os.path.basename(video_path)
    video_name_only = os.path.splitext(video_filename)[0]
    save_path = os.path.join(SNAPSHOT_DIR, video_name_only)
    if not os.path.exists(save_path): os.makedirs(save_path)

    best_frame = None       
    max_score = 0.0         
    is_falling_sequence = False 
    
    # Bi·∫øn ƒë·ªÉ ki·ªÉm so√°t vi·ªác l∆∞u (tr√°nh l∆∞u qu√° nhi·ªÅu tr√πng l·∫∑p)
    last_saved_time = 0 

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret: 
            break # Video k·∫øt th√∫c
        
        # Resize nh·∫π 
        frame = cv2.resize(frame, (640, 480))
        
        # --- G·ªåI AI ---
        processed_frame, fall_count, score = detector.process_frame(frame)
        current_settings["fall_detected_now"] = (fall_count > 0)

        # --- LOGIC BEST SHOT (ƒê√É S·ª¨A) ---
        if fall_count > 0:
            current_time = time.time()
            
            # N·∫øu l√† b·∫Øt ƒë·∫ßu sequence m·ªõi
            if not is_falling_sequence:
                is_falling_sequence = True
                max_score = 0.0
                best_frame = None
                print("‚ö†Ô∏è Fall Started - Tracking best shot...")

            # C·∫≠p nh·∫≠t khung h√¨nh t·ªët nh·∫•t n·∫øu ƒëi·ªÉm cao h∆°n
            if score >= max_score:
                max_score = score
                best_frame = processed_frame.copy()
                
                # OPTIONAL: L∆∞u ngay l·∫≠p t·ª©c n·∫øu score r·∫•t cao (>0.85) ƒë·ªÉ hi·ªÉn th·ªã ngay tr√™n Dashboard
                # Thay v√¨ ch·ªù ng√£ xong m·ªõi hi·ªán.
                if max_score > 0.85 and (current_time - last_saved_time > 1.0):
                    save_evidence(best_frame, max_score, save_path)
                    last_saved_time = current_time

        else:
            # Ng∆∞·ªùi ƒë√£ ƒë·ª©ng d·∫≠y ho·∫∑c h·∫øt ng√£
            if is_falling_sequence:
                print("‚úÖ Fall Sequence Ended. Saving final best shot.")
                # L∆∞u c√°i t·ªët nh·∫•t c√≤n l·∫°i trong sequence
                save_evidence(best_frame, max_score, save_path)
                
                # Reset
                is_falling_sequence = False
                best_frame = None
                max_score = 0.0

        # Encode frame g·ª≠i v·ªÅ Client
        ret, buffer = cv2.imencode('.jpg', processed_frame)
        frame_bytes = buffer.tobytes()
        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
    
    # --- QUAN TR·ªåNG: X·ª¨ L√ù KHI LOOP K·∫æT TH√öC (Video h·∫øt) ---
    # N·∫øu video h·∫øt m√† v·∫´n ƒëang trong tr·∫°ng th√°i ng√£ -> L∆ØU NGAY
    if is_falling_sequence and best_frame is not None:
        print("‚èπÔ∏è Video Ended during fall. Saving pending evidence.")
        save_evidence(best_frame, max_score, save_path)

    cap.release()

@app.get("/video_feed")
def video_feed(video_path: str):
    return StreamingResponse(
        generate_frames(video_path), 
        media_type="multipart/x-mixed-replace; boundary=frame"
    )

if __name__ == "__main__":
    import numpy as np # Import th√™m ·ªü ƒë√¢y n·∫øu ch∆∞a c√≥ global import
    uvicorn.run(app, host="0.0.0.0", port=8000)